{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fdad45-819d-4fa5-896b-9d306589b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Stock Management System - Feature Engineering\n",
      "============================================================\n",
      "Step 1: Loading and Enhancing Data\n",
      "============================================================\n",
      "Loaded existing data: (2824, 49)\n",
      "Date range: 2023-01-03 to 2025-10-24\n",
      "Symbols: ['AAPL', 'AMZN', 'MSFT', 'SPY']\n",
      "\n",
      "============================================================\n",
      "Step 2: Advanced Feature Engineering\n",
      "============================================================\n",
      "Creating price-based features...\n",
      "Creating volume-based features...\n",
      "Creating market regime features...\n",
      "Creating enhanced sentiment features...\n",
      "Creating technical pattern features...\n",
      "Creating risk-adjusted features...\n",
      "Created 34 new advanced features\n",
      "Enhanced dataset: (2824, 83)\n",
      "\n",
      "============================================================\n",
      "Step 3: Smart Target Engineering\n",
      "============================================================\n",
      "Creating directional targets...\n",
      "Creating magnitude targets...\n",
      "Creating relative performance targets...\n",
      "Creating risk-adjusted targets...\n",
      "Creating regime-specific targets...\n",
      "Created multiple sophisticated targets\n",
      "Dataset with targets: (2824, 92)\n",
      "\n",
      "============================================================\n",
      "Step 4: Feature Selection & Validation\n",
      "============================================================\n",
      "Selected 25 most predictive features\n",
      "Top 10 features by correlation:\n",
      "   price_vs_MA_200               : 0.0729\n",
      "   trend_persistence             : 0.0624\n",
      "   price_vs_support_20d          : 0.0530\n",
      "   RSI_14                        : 0.0519\n",
      "   MA_alignment_strength         : 0.0456\n",
      "   contrarian_sentiment          : 0.0418\n",
      "   volume_MA_10                  : 0.0367\n",
      "   volume                        : 0.0301\n",
      "   volume_climax                 : 0.0296\n",
      "Total features available: 25\n",
      "\n",
      "============================================================\n",
      "Step 5: Final Dataset Preparation\n",
      "============================================================\n",
      "Final dataset: (2824, 35)\n",
      "Enhanced dataset saved: enhanced_trading_dataset_v2.db\n",
      "\n",
      "============================================================\n",
      "Step 6: Dataset Analysis\n",
      "============================================================\n",
      "Target Distribution:\n",
      "   5-Day UP: 60.8%\n",
      "   Strong Moves: 40.0%\n",
      "   Beat SPY: 39.9%\n",
      "\n",
      "Feature Categories:\n",
      "   Momentum       : 2 features\n",
      "   Volatility     : 2 features\n",
      "   Price_Level    : 9 features\n",
      "   Volume         : 5 features\n",
      "   Sentiment      : 2 features\n",
      "   Technical      : 8 features\n",
      "\n",
      "Symbol Performance:\n",
      "   AAPL:\n",
      "      Records: 706\n",
      "      Win Rate: 58.5%\n",
      "      Beat SPY: 52.7%\n",
      "   AMZN:\n",
      "      Records: 706\n",
      "      Win Rate: 59.5%\n",
      "      Beat SPY: 53.3%\n",
      "   MSFT:\n",
      "      Records: 706\n",
      "      Win Rate: 61.3%\n",
      "      Beat SPY: 53.7%\n",
      "   SPY:\n",
      "      Records: 706\n",
      "      Win Rate: 63.7%\n",
      "      Beat SPY: 0.0%\n",
      "\n",
      "Market Regime Distribution:\n",
      "   MEDIUM         : 1142 records (40.4%)\n",
      "   HIGH           : 841 records (29.8%)\n",
      "   LOW            : 841 records (29.8%)\n",
      "\n",
      "============================================================\n",
      "Enhanced Data Pipeline Complete!\n",
      "============================================================\n",
      "\n",
      "Ready for Advanced Modeling:\n",
      "   Records: 2824\n",
      "   Features: 25\n",
      "   Targets: Multiple trading strategies\n",
      "   Symbols: 4 diversified assets\n",
      "   Data Quality: Enhanced\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 01_Feature_Engineering.ipynb\n",
    "# Advanced Feature Engineering for Stock Prediction\n",
    "# ==================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"AI Stock Management System - Feature Engineering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Step 1: Loading and Enhancing Data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def load_and_enhance_data():\n",
    "    \"\"\"Load existing data and add sophisticated features\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"hybrid_ai_management_system_FIXED.db\")\n",
    "        df = pd.read_sql(\"SELECT * FROM hybrid_trading_data\", conn)\n",
    "        conn.close()\n",
    "        \n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        print(f\"Loaded existing data: {df.shape}\")\n",
    "        print(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "        print(f\"Symbols: {df['symbol'].unique().tolist()}\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load data\n",
    "df = load_and_enhance_data()\n",
    "\n",
    "if df is None:\n",
    "    print(\"No data available\")\n",
    "    exit()\n",
    "\n",
    "# ==================================================\n",
    "# Step 2: Advanced Feature Engineering\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 2: Advanced Feature Engineering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def create_advanced_features(df):\n",
    "    \"\"\"Create sophisticated trading features\"\"\"\n",
    "    df_advanced = df.copy()\n",
    "    df_advanced = df_advanced.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # 1. Price-based features\n",
    "    print(\"Creating price-based features...\")\n",
    "    \n",
    "    # A. Advanced Momentum\n",
    "    df_advanced['momentum_acceleration'] = df_advanced.groupby('symbol')['return_5d'].diff()\n",
    "    df_advanced['price_velocity'] = df_advanced['return_5d'] - df_advanced['return_10d']\n",
    "    df_advanced['trend_persistence'] = (df_advanced['return_5d'] * df_advanced['return_10d'] > 0).astype(int)\n",
    "    \n",
    "    # B. Support/Resistance Levels\n",
    "    for window in [10, 20, 50]:\n",
    "        df_advanced[f'support_{window}d'] = df_advanced.groupby('symbol')['low'].rolling(window).min().reset_index(level=0, drop=True)\n",
    "        df_advanced[f'resistance_{window}d'] = df_advanced.groupby('symbol')['high'].rolling(window).max().reset_index(level=0, drop=True)\n",
    "        df_advanced[f'price_vs_support_{window}d'] = (df_advanced['close'] - df_advanced[f'support_{window}d']) / df_advanced[f'support_{window}d']\n",
    "        df_advanced[f'price_vs_resistance_{window}d'] = (df_advanced[f'resistance_{window}d'] - df_advanced['close']) / df_advanced['close']\n",
    "    \n",
    "    # 2. Volume-based features\n",
    "    print(\"Creating volume-based features...\")\n",
    "    \n",
    "    # A. Volume Confirmation\n",
    "    df_advanced['volume_trend'] = (df_advanced.groupby('symbol')['volume'].rolling(5).mean().reset_index(level=0, drop=True) > \n",
    "                                  df_advanced.groupby('symbol')['volume'].rolling(20).mean().reset_index(level=0, drop=True)).astype(int)\n",
    "    df_advanced['volume_price_alignment'] = (df_advanced['daily_return'] * df_advanced['volume_zscore'] > 0).astype(int)\n",
    "    \n",
    "    # B. Smart Money Indicators\n",
    "    df_advanced['large_volume_spike'] = (df_advanced['volume'] > df_advanced.groupby('symbol')['volume'].rolling(20).mean().reset_index(level=0, drop=True) * 2).astype(int)\n",
    "    df_advanced['volume_climax'] = (df_advanced['volume'] > df_advanced.groupby('symbol')['volume'].rolling(50).quantile(0.9).reset_index(level=0, drop=True)).astype(int)\n",
    "    \n",
    "    # 3. Market regime features\n",
    "    print(\"Creating market regime features...\")\n",
    "    \n",
    "    # A. Volatility Regime\n",
    "    df_advanced['volatility_regime'] = np.where(\n",
    "        df_advanced['volatility_10d'] > df_advanced['volatility_10d'].quantile(0.7), 'HIGH',\n",
    "        np.where(df_advanced['volatility_10d'] < df_advanced['volatility_10d'].quantile(0.3), 'LOW', 'MEDIUM')\n",
    "    )\n",
    "    \n",
    "    # B. Trend Regime\n",
    "    df_advanced['trend_regime'] = np.where(\n",
    "        df_advanced['price_vs_MA_50'] > 0.05, 'STRONG_UP',\n",
    "        np.where(df_advanced['price_vs_MA_50'] < -0.05, 'STRONG_DOWN', 'SIDEWAYS')\n",
    "    )\n",
    "    \n",
    "    # C. Market Health (SPY trend)\n",
    "    spy_data = df_advanced[df_advanced['symbol'] == 'SPY'][['date', 'close']].copy()\n",
    "    spy_data['SPY_trend'] = (spy_data['close'] > spy_data['close'].rolling(50).mean()).astype(int)\n",
    "    df_advanced = df_advanced.merge(spy_data[['date', 'SPY_trend']], on='date', how='left')\n",
    "    \n",
    "    # 4. Enhanced sentiment features\n",
    "    print(\"Creating enhanced sentiment features...\")\n",
    "    \n",
    "    # A. Contextual Sentiment\n",
    "    df_advanced['sentiment_in_trend'] = (df_advanced['sentiment_with_momentum'] * df_advanced['return_5d'] > 0).astype(int)\n",
    "    df_advanced['contrarian_sentiment'] = (df_advanced['sentiment_with_momentum'] * df_advanced['return_5d'] < 0).astype(int)\n",
    "    \n",
    "    # B. Sentiment Regimes\n",
    "    df_advanced['sentiment_regime'] = np.where(\n",
    "        df_advanced['sentiment_with_momentum'].abs() > 0.15, 'HIGH_SENTIMENT',\n",
    "        np.where(df_advanced['sentiment_with_momentum'].abs() < 0.05, 'LOW_SENTIMENT', 'MODERATE_SENTIMENT')\n",
    "    )\n",
    "    \n",
    "    # 5. Technical pattern features\n",
    "    print(\"Creating technical pattern features...\")\n",
    "    \n",
    "    # A. RSI Patterns\n",
    "    df_advanced['RSI_divergence'] = (\n",
    "        (df_advanced['RSI_14'] > df_advanced['RSI_14'].shift(5)) & \n",
    "        (df_advanced['close'] < df_advanced['close'].shift(5))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # B. Moving Average Patterns\n",
    "    df_advanced['MA_alignment_strength'] = (\n",
    "        (df_advanced['MA_5'] > df_advanced['MA_20']).astype(int) +\n",
    "        (df_advanced['MA_20'] > df_advanced['MA_50']).astype(int) +\n",
    "        (df_advanced['MA_50'] > df_advanced['MA_200']).astype(int)\n",
    "    )\n",
    "    \n",
    "    # C. Breakout Detection\n",
    "    df_advanced['breakout_20d_high'] = (df_advanced['close'] > df_advanced.groupby('symbol')['high'].rolling(20).max().shift(1).reset_index(level=0, drop=True)).astype(int)\n",
    "    df_advanced['breakdown_20d_low'] = (df_advanced['close'] < df_advanced.groupby('symbol')['low'].rolling(20).min().shift(1).reset_index(level=0, drop=True)).astype(int)\n",
    "    \n",
    "    # 6. Risk-adjusted features\n",
    "    print(\"Creating risk-adjusted features...\")\n",
    "    \n",
    "    # A. Sharpe-like ratios\n",
    "    df_advanced['volatility_5d'] = df_advanced.groupby('symbol')['daily_return'].rolling(5).std().reset_index(level=0, drop=True)\n",
    "    df_advanced['return_to_volatility_5d'] = df_advanced['return_5d'] / (df_advanced['volatility_5d'] + 0.001)\n",
    "    df_advanced['return_to_volatility_10d'] = df_advanced['return_10d'] / (df_advanced['volatility_10d'] + 0.001)\n",
    "    \n",
    "    # B. Drawdown Features\n",
    "    df_advanced['rolling_max'] = df_advanced.groupby('symbol')['close'].rolling(20).max().reset_index(level=0, drop=True)\n",
    "    df_advanced['current_drawdown'] = (df_advanced['close'] - df_advanced['rolling_max']) / df_advanced['rolling_max']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    numeric_cols = df_advanced.select_dtypes(include=[np.number]).columns\n",
    "    df_advanced[numeric_cols] = df_advanced.groupby('symbol')[numeric_cols].ffill().fillna(0)\n",
    "    \n",
    "    print(f\"Created {df_advanced.shape[1] - df.shape[1]} new advanced features\")\n",
    "    return df_advanced\n",
    "\n",
    "# Apply advanced feature engineering\n",
    "enhanced_df = create_advanced_features(df)\n",
    "print(f\"Enhanced dataset: {enhanced_df.shape}\")\n",
    "\n",
    "# ==================================================\n",
    "# Step 3: Smart Target Engineering\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 3: Smart Target Engineering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def create_smart_targets(df):\n",
    "    \"\"\"Create multiple sophisticated trading targets\"\"\"\n",
    "    df_targets = df.copy()\n",
    "    \n",
    "    # 1. Directional targets\n",
    "    print(\"Creating directional targets...\")\n",
    "    \n",
    "    # A. Basic Direction (rename to avoid conflicts)\n",
    "    df_targets['target_direction_5d'] = (df_targets['future_return_5d'] > 0).astype(int)\n",
    "    \n",
    "    # B. Strong Move Target (filter out noise)\n",
    "    strong_threshold = df_targets['future_return_5d'].abs().quantile(0.6)\n",
    "    df_targets['target_strong_5d'] = (\n",
    "        (df_targets['future_return_5d'] > strong_threshold) | \n",
    "        (df_targets['future_return_5d'] < -strong_threshold)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 2. Magnitude targets (Regression)\n",
    "    print(\"Creating magnitude targets...\")\n",
    "    \n",
    "    df_targets['target_magnitude_5d'] = df_targets['future_return_5d'].abs()\n",
    "    df_targets['target_high_vol_5d'] = (df_targets['target_magnitude_5d'] > 0.03).astype(int)\n",
    "    \n",
    "    # 3. Relative performance targets\n",
    "    print(\"Creating relative performance targets...\")\n",
    "    \n",
    "    # Beat SPY target\n",
    "    spy_returns = df_targets[df_targets['symbol'] == 'SPY'][['date', 'future_return_5d']].rename(\n",
    "        columns={'future_return_5d': 'SPY_future_return_5d'}\n",
    "    )\n",
    "    df_targets = df_targets.merge(spy_returns, on='date', how='left')\n",
    "    df_targets['target_beat_spy_5d'] = (df_targets['future_return_5d'] > df_targets['SPY_future_return_5d']).astype(int)\n",
    "    \n",
    "    # 4. Risk-adjusted targets\n",
    "    print(\"Creating risk-adjusted targets...\")\n",
    "    \n",
    "    df_targets['target_sharpe_5d'] = df_targets['future_return_5d'] / (df_targets['volatility_5d'] + 0.001)\n",
    "    df_targets['target_good_risk_5d'] = (df_targets['target_sharpe_5d'] > 1.0).astype(int)\n",
    "    \n",
    "    # 5. Regime-specific targets\n",
    "    print(\"Creating regime-specific targets...\")\n",
    "    \n",
    "    # High volatility regime target\n",
    "    high_vol_mask = df_targets['volatility_regime'] == 'HIGH'\n",
    "    df_targets['target_high_vol_success'] = ((df_targets['future_return_5d'].abs() > 0.02) & high_vol_mask).astype(int)\n",
    "    \n",
    "    print(\"Created multiple sophisticated targets\")\n",
    "    return df_targets\n",
    "\n",
    "# Apply smart target engineering\n",
    "targeted_df = create_smart_targets(enhanced_df)\n",
    "print(f\"Dataset with targets: {targeted_df.shape}\")\n",
    "\n",
    "# ==================================================\n",
    "# Step 4: Feature Selection & Validation\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 4: Feature Selection & Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def select_best_features(df, target_column='target_direction_5d'):\n",
    "    \"\"\"Select most predictive features\"\"\"\n",
    "    \n",
    "    # Features to exclude (metadata, future data, targets, etc.)\n",
    "    exclude_features = [\n",
    "        'symbol', 'name', 'category', 'has_sentiment', 'date',\n",
    "        'target_strong_5d', 'target_magnitude_5d', 'target_high_vol_5d', \n",
    "        'SPY_future_return_5d', 'target_beat_spy_5d', 'target_sharpe_5d', \n",
    "        'target_good_risk_5d', 'target_high_vol_success',\n",
    "        'future_return_5d', 'future_return_10d', 'future_return_21d',\n",
    "        'target_5d_binary', 'target_10d_binary', 'target_21d_binary',  # Remove old targets\n",
    "        'target_5d_strong', 'target_10d_strong', 'target_21d_strong'   # Remove old targets\n",
    "    ]\n",
    "    \n",
    "    # Get numeric features\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "    candidate_features = [f for f in numeric_features if f not in exclude_features]\n",
    "    \n",
    "    # Calculate feature correlations with target\n",
    "    correlations = []\n",
    "    for feature in candidate_features:\n",
    "        try:\n",
    "            corr = abs(df[feature].corr(df[target_column]))\n",
    "            if not np.isnan(corr):\n",
    "                correlations.append((feature, corr))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Sort by correlation strength\n",
    "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select top features (excluding the target itself)\n",
    "    top_features = []\n",
    "    for feature, corr in correlations:\n",
    "        if feature != target_column and len(top_features) < 25:\n",
    "            top_features.append(feature)\n",
    "    \n",
    "    print(f\"Selected {len(top_features)} most predictive features\")\n",
    "    print(f\"Top 10 features by correlation:\")\n",
    "    for feature, corr in correlations[:10]:\n",
    "        if feature != target_column:\n",
    "            print(f\"   {feature:30}: {corr:.4f}\")\n",
    "    \n",
    "    return top_features\n",
    "\n",
    "# Select best features\n",
    "best_features = select_best_features(targeted_df)\n",
    "print(f\"Total features available: {len(best_features)}\")\n",
    "\n",
    "# ==================================================\n",
    "# Step 5: Final Dataset Preparation\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 5: Final Dataset Preparation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create final dataset - use unique target names\n",
    "final_columns = ['symbol', 'name', 'category', 'date'] + best_features + [\n",
    "    'target_direction_5d', 'target_strong_5d', 'target_magnitude_5d', \n",
    "    'target_beat_spy_5d', 'volatility_regime', 'trend_regime'\n",
    "]\n",
    "\n",
    "# Ensure all columns exist\n",
    "available_columns = [col for col in final_columns if col in targeted_df.columns]\n",
    "final_df = targeted_df[available_columns]\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "final_df = final_df.dropna()\n",
    "print(f\"Final dataset: {final_df.shape}\")\n",
    "\n",
    "# Save enhanced dataset\n",
    "conn = sqlite3.connect(\"enhanced_trading_dataset_v2.db\")\n",
    "final_df.to_sql(\"enhanced_trading_data\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Save feature metadata\n",
    "feature_metadata = pd.DataFrame({\n",
    "    'feature_name': best_features,\n",
    "    'feature_type': 'ENHANCED_FEATURE',\n",
    "    'category': 'TECHNICAL_INDICATOR'\n",
    "})\n",
    "feature_metadata.to_sql(\"feature_metadata\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"Enhanced dataset saved: enhanced_trading_dataset_v2.db\")\n",
    "\n",
    "# ==================================================\n",
    "# Step 6: Dataset Analysis\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 6: Dataset Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Target Distribution:\")\n",
    "print(f\"   5-Day UP: {final_df['target_direction_5d'].mean():.1%}\")\n",
    "print(f\"   Strong Moves: {final_df['target_strong_5d'].mean():.1%}\")\n",
    "print(f\"   Beat SPY: {final_df['target_beat_spy_5d'].mean():.1%}\")\n",
    "\n",
    "print(f\"\\nFeature Categories:\")\n",
    "feature_categories = {\n",
    "    'Momentum': len([f for f in best_features if 'momentum' in f or 'return' in f]),\n",
    "    'Volatility': len([f for f in best_features if 'volatility' in f]),\n",
    "    'Price_Level': len([f for f in best_features if 'price_vs' in f or 'support' in f or 'resistance' in f]),\n",
    "    'Volume': len([f for f in best_features if 'volume' in f]),\n",
    "    'Sentiment': len([f for f in best_features if 'sentiment' in f]),\n",
    "    'Technical': len([f for f in best_features if 'RSI' in f or 'MA_' in f or 'break' in f])\n",
    "}\n",
    "\n",
    "for category, count in feature_categories.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {category:15}: {count} features\")\n",
    "\n",
    "print(f\"\\nSymbol Performance:\")\n",
    "for symbol in final_df['symbol'].unique():\n",
    "    symbol_data = final_df[final_df['symbol'] == symbol]\n",
    "    print(f\"   {symbol}:\")\n",
    "    print(f\"      Records: {len(symbol_data)}\")\n",
    "    print(f\"      Win Rate: {symbol_data['target_direction_5d'].mean():.1%}\")\n",
    "    if 'target_beat_spy_5d' in symbol_data.columns:\n",
    "        print(f\"      Beat SPY: {symbol_data['target_beat_spy_5d'].mean():.1%}\")\n",
    "\n",
    "if 'volatility_regime' in final_df.columns:\n",
    "    print(f\"\\nMarket Regime Distribution:\")\n",
    "    regime_counts = final_df['volatility_regime'].value_counts()\n",
    "    for regime, count in regime_counts.items():\n",
    "        print(f\"   {regime:15}: {count} records ({count/len(final_df):.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Enhanced Data Pipeline Complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nReady for Advanced Modeling:\")\n",
    "print(f\"   Records: {len(final_df)}\")\n",
    "print(f\"   Features: {len(best_features)}\")\n",
    "print(f\"   Targets: Multiple trading strategies\")\n",
    "print(f\"   Symbols: {final_df['symbol'].nunique()} diversified assets\")\n",
    "print(f\"   Data Quality: Enhanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669ed13-5316-4d12-9204-69d76806a1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stock)",
   "language": "python",
   "name": "stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
